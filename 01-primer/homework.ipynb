{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Homework\n",
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page), but instead of \"Green Taxi Trip Records\", we'll use \"For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Download the data for January and February 2021.\n",
    "\n",
    "Note that you need \"For-Hire Vehicle Trip Records\", not \"High Volume For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Read the data for January. How many records are there?\n",
    "\n",
    "* 1054112\n",
    "* 1154112\n",
    "* 1254112\n",
    "* 1354112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jan = pd.read_parquet('data/fhv_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,154,112 records\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {df_jan.shape[0]:,} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the average trip duration in January?\n",
    "\n",
    "* 15.16\n",
    "* 19.16\n",
    "* 24.16\n",
    "* 29.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create field duration of taxi rides in minutes\n",
    "df_jan['duration'] = (df_jan.dropOff_datetime - df_jan.pickup_datetime).dt.total_seconds().div(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average trip duration in January is 19.167 minutes.\n"
     ]
    }
   ],
   "source": [
    "print(f'The average trip duration in January is {df_jan.duration.mean():,.3f} minutes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data preparation\n",
    "\n",
    "Check the distribution of the duration variable. There are some outliers. \n",
    "\n",
    "Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "How many records did you drop? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['a', 'b', 'c']\n",
    "all(x in a for x in ['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if not filename.endswith('.parquet'):\n",
    "        Exception('filetype not supported')\n",
    "    \n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    if any(x not in df.columns for x in ['PUlocationID', 'DOlocationID', 'dropOff_datetime', 'pickup_datetime']):\n",
    "        Exception('columns missing')\n",
    "\n",
    "    # create field duration of taxi rides in minutes\n",
    "    df['duration'] = (df.dropOff_datetime - df.pickup_datetime).dt.total_seconds().div(60)\n",
    "    \n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PUlocationID', 'DOlocationID']\n",
    "    df[categorical] = df[categorical].fillna(-1).astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('data/fhv_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have dropped 44,286 values (3.8%).\n"
     ]
    }
   ],
   "source": [
    "print(f'We have dropped {df_jan.shape[0] - df_train.shape[0]:,} values ({(df_jan.shape[0] - df_train.shape[0])/df_jan.shape[0]*100:.1f}%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q3. Missing values\n",
    "\n",
    "The features we'll use for our model are the pickup and dropoff location IDs. \n",
    "\n",
    "But they have a lot of missing values there. Let's replace them with \"-1\".\n",
    "\n",
    "What's the fractions of missing values for the pickup location ID? I.e. fraction of \"-1\"s after you filled the NAs.\n",
    "\n",
    "* 53%\n",
    "* 63%\n",
    "* 73%\n",
    "* 83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'83.5%'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.PUlocationID.eq('-1.0').value_counts(normalize=True).mul(100)[1].round(1).astype(str)+'%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix? (The number of columns).\n",
    "\n",
    "* 2\n",
    "* 152\n",
    "* 352\n",
    "* 525\n",
    "* 725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dicts = df_train[['PUlocationID', 'DOlocationID']].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix has 525 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'The matrix has {X_train.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters \n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* 5.52\n",
    "* 10.52\n",
    "* 15.52\n",
    "* 20.52\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.528519107204616"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "mean_squared_error(y_train, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (Feb 2021). \n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "* 6.01\n",
    "* 11.01\n",
    "* 16.01\n",
    "* 21.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = read_dataframe('data/fhv_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.01428315568312"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dicts = df_test[['PUlocationID', 'DOlocationID']].to_dict(orient='records')\n",
    "\n",
    "X_test = dv.transform(test_dicts)\n",
    "\n",
    "target = 'duration'\n",
    "y_test = df_test[target].values\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test, y_pred, squared=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f2f952d8aa9dcd886a3973de0287cb063d799d9615b9da83119a2c40929314a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('linear_regression_nyc_taxi-R0Y3TRRH-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
